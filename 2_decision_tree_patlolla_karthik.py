# -*- coding: utf-8 -*-
"""2_Decision-Tree_Parth-Gupta

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xHh-MB7jK9SoOZIQeEGvHuRZt-69vB9q

### Decision Tree (Titanic Dataset)
"""

import numpy as np                       # For numerical operations and efficient array handling
import pandas as pd                      # For tabular data manipulation
import matplotlib.pyplot as plt          # For plotting confusion matrix and tree
import seaborn as sns                    # For heatmaps
from sklearn.tree import DecisionTreeClassifier, plot_tree # Decision Tree model and visualization
from sklearn.model_selection import train_test_split       # For splitting train/test
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# getting dataset from public csv
url = "https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv"
df = pd.read_csv(url)
print("=== Titanic Data Loaded ===")
print(df.head())

# Select features commonly used for survival prediction
features = ["Pclass", "Sex", "Age", "SibSp", "Parch", "Fare", "Embarked"]
data = df[features]

df.info()

data["Age"].fillna(data["Age"].median(), inplace=True)              # Set missing ages to median age
data["Embarked"].fillna(data["Embarked"].mode()[0], inplace=True)   # Set missing embarkation to most common

# Encode categorical variables as numbers
data["Sex"] = data["Sex"].map({"male": 0, "female": 1})             # Male:0, Female:1
data["Embarked"] = data["Embarked"].map({"S": 0, "C": 1, "Q": 2})   # S:0, C:1, Q:2

X = data.values                             # Feature matrix for the model
y = df["Survived"].values

print("=== Feature Summary ===")
print(f"Columns used: {features}")
print(f"Shape of feature matrix: {X.shape}")
print(f"Class distribution (Survived counts): {np.bincount(y)}")

# Split dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.3,                          # 30% test, 70% train
    random_state=42,                        # Reproducibility
    stratify=y                              # Balanced class distribution
)
print(f"Train samples: {X_train.shape[0]}, Test samples: {X_test.shape[0]}")

#Decision Tree model
model = DecisionTreeClassifier(
    max_depth=5,          # Limit tree depth to avoid overfitting, but still capture non-linearity
    random_state=42
)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

print("=== Model Evaluation ===")
print(f"Accuracy on test set: {accuracy_score(y_test, y_pred):.2f}")
print("\nClassification Report:")
print(classification_report(y_test, y_pred, target_names=["Not Survived", "Survived"]))

# the confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6,4))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',
            xticklabels=["Not Survived", "Survived"],
            yticklabels=["Not Survived", "Survived"])
plt.title("Confusion Matrix (Decision Tree on Titanic)")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.tight_layout()
plt.show()

# the trained Decision Tree
plt.figure(figsize=(18,8))
plot_tree(
    model,
    feature_names=features,
    class_names=["Not Survived", "Survived"],
    filled=True,
    rounded=True,
    fontsize=10
)
plt.title("Decision Tree Structure")
plt.show()

# Predict survival for a hypothetical passenger
# Example: [Pclass=3, Sex=1 (female), Age=25, SibSp=0, Parch=0, Fare=10, Embarked=0 (S)]
sample = np.array([[3, 1, 25, 0, 0, 10, 0]])
sample_pred = model.predict(sample)
print("=== Sample Passenger Prediction ===")
print(f"Input: {sample.tolist()}")
print(f"Predicted class (0=Not Survived, 1=Survived): {sample_pred[0]}")